3:I[91117,[],""]
5:I[93874,[],""]
6:I[93598,["410","static/chunks/410-dfbfd00e58277561.js","8227","static/chunks/8227-c7f40788707044e3.js","2839","static/chunks/app/(navigation)/presets/layout-1069dc4d9a8fbe9d.js"],"ToastProvider"]
7:I[93598,["410","static/chunks/410-dfbfd00e58277561.js","8227","static/chunks/8227-c7f40788707044e3.js","2839","static/chunks/app/(navigation)/presets/layout-1069dc4d9a8fbe9d.js"],"ToastViewport"]
8:I[61454,["9799","static/chunks/ec2b4425-50329b410e00a9c1.js","410","static/chunks/410-dfbfd00e58277561.js","8147","static/chunks/8147-2d2d9a18bcb26f63.js","4943","static/chunks/4943-35d31b66abf795bc.js","9845","static/chunks/9845-90dbd3909d8334b6.js","1454","static/chunks/1454-85873996a062b942.js","294","static/chunks/app/(navigation)/layout-45d286406f251942.js"],"Navigation"]
9:I[32948,["410","static/chunks/410-dfbfd00e58277561.js","8147","static/chunks/8147-2d2d9a18bcb26f63.js","8391","static/chunks/8391-8e80deddf75f281d.js","3185","static/chunks/app/layout-b5125eba966e217b.js"],"TooltipProvider"]
a:I[60663,["410","static/chunks/410-dfbfd00e58277561.js","8147","static/chunks/8147-2d2d9a18bcb26f63.js","8391","static/chunks/8391-8e80deddf75f281d.js","3185","static/chunks/app/layout-b5125eba966e217b.js"],"Log"]
b:I[89845,["9845","static/chunks/9845-90dbd3909d8334b6.js","9160","static/chunks/app/not-found-0db911bd4ddab356.js"],""]
c:I[51146,["410","static/chunks/410-dfbfd00e58277561.js","8147","static/chunks/8147-2d2d9a18bcb26f63.js","8391","static/chunks/8391-8e80deddf75f281d.js","3185","static/chunks/app/layout-b5125eba966e217b.js"],"Analytics"]
4:["slug","python-technical-interview-expert","d"]
0:["9WXB-plA3UbkbuvRNKH_I",[[["",{"children":["(navigation)",{"children":["presets",{"children":["preset",{"children":[["slug","python-technical-interview-expert","d"],{"children":["__PAGE__?{\"slug\":\"python-technical-interview-expert\"}",{}]}]}]}]}]},"$undefined","$undefined",true],["",{"children":["(navigation)",{"children":["presets",{"children":["preset",{"children":[["slug","python-technical-interview-expert","d"],{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","(navigation)","children","presets","children","preset","children","$4","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","(navigation)","children","presets","children","preset","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","$L6",null,{"children":[["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","(navigation)","children","presets","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}]," ",["$","$L7",null,{}]]}],null],null]},[["$","div",null,{"className":"h-full","children":[["$","$L8",null,{}],["$","main",null,{"className":"flex flex-col min-h-full pt-[50px]","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","(navigation)","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/9eac01cf7d41811b.css","precedence":"next","crossOrigin":"$undefined"}]]}]}]]}],null],[["$","div",null,{"className":"fixed top-[49px] w-[600px] h-[1px] z-50 -left-[200px]","style":{"backgroundImage":"linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255,255,255,0.3), rgba(255, 255, 255, 0))","animation":"flash 2s ease-in-out infinite"}}],[],[]]]},[["$","html",null,{"lang":"en","className":"dark","style":{"colorScheme":"dark"},"children":[["$","$L9",null,{"children":["$","body",null,{"className":"isolate","children":[["$","$La",null,{}],["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-center justify-center h-full gap-4","children":[["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 16 16","className":"w-12 h-12 flicker","children":["$","path",null,{"fill":"currentColor","fillRule":"evenodd","d":"M4.502 10.037v1.46L1 7.996l.734-.728 2.768 2.77Zm1.461 1.46h-1.46L8.004 15l.73-.73-2.772-2.772ZM14.27 8.73 15 8 8.002 1l-.73.73 2.765 2.77H8.365l-1.93-1.93-.73.73 1.201 1.202H6.07v5.431h5.43v-.84l1.203 1.203.73-.73-1.932-1.933V5.961l2.77 2.768ZM4.868 4.134l-.73.73.783.784.73-.73-.783-.784Zm6.215 6.215-.728.73.784.783.73-.73-.786-.783ZM3.3 5.701l-.73.73 1.931 1.933V6.902l-1.2-1.2Zm5.797 5.797H7.636l1.932 1.932.73-.731-1.2-1.201Z","clipRule":"evenodd"}]}],["$","div",null,{"className":"flex flex-col gap-1 items-center","children":[["$","h2",null,{"className":"text-2xl font-medium","children":"Not Found"}],["$","p",null,{"className":"text-gray-10","children":"Could not find requested resource"}]]}],["$","$Lb",null,{"href":"/","children":"Go home","className":"inline-flex shrink-0 items-center justify-center whitespace-nowrap font-medium transition-colors duration-100 overflow-hidden focus-visible:outline-none focus-visible:ring-1 hover:cursor-default disabled:pointer-events-none disabled:opacity-50 bg-gray-a3 text-gray-a11 hover:bg-gray-a4 hover:text-gray-12 shadow-[inset_0_0_0_1px_var(--gray-a2)] focus-visible:ring-gray-a7 focus-visible:shadow-[inset_0_0_0_1px_var(--gray-a7)] h-[30px] rounded-md px-3 text-sm gap-1.5"}]]}],"notFoundStyles":[],"styles":null}]]}]}],["$","$Lc",null,{}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/3cae8fa9b89a3036.css","precedence":"next","crossOrigin":"$undefined"}]],"$Ld"]]]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"name":"theme-color","content":"#181818"}],["$","meta","2",{"charSet":"utf-8"}],["$","title","3",{"children":"Technical Interview Expert - Raycast AI Preset"}],["$","meta","4",{"name":"description","content":"A Python Expert helping you through technical interview questions."}],["$","meta","5",{"name":"twitter:label1","content":"Model"}],["$","meta","6",{"name":"twitter:data","content":"openai-gpt-4o"}],["$","meta","7",{"name":"twitter:label2","content":"Creativity"}],["$","meta","8",{"name":"twitter:data2","content":"low"}],["$","meta","9",{"property":"og:title","content":"Technical Interview Expert - Raycast AI Preset"}],["$","meta","10",{"property":"og:description","content":"A Python Expert helping you through technical interview questions."}],["$","meta","11",{"property":"og:url","content":"http://localhost:3000/presets/preset/python-technical-interview-expert"}],["$","meta","12",{"property":"og:site_name","content":"Ray.so"}],["$","meta","13",{"property":"og:image","content":"http://localhost:3000/presets/og?title=Technical%20Interview%20Expert&description=A%20Python%20Expert%20helping%20you%20through%20technical%20interview%20questions.&icon=brand-python"}],["$","meta","14",{"property":"og:type","content":"website"}],["$","meta","15",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","16",{"name":"twitter:creator","content":"@raycastapp"}],["$","meta","17",{"name":"twitter:title","content":"Technical Interview Expert - Raycast AI Preset"}],["$","meta","18",{"name":"twitter:description","content":"A Python Expert helping you through technical interview questions."}],["$","meta","19",{"name":"twitter:image","content":"http://localhost:3000/presets/og?title=Technical%20Interview%20Expert&description=A%20Python%20Expert%20helping%20you%20through%20technical%20interview%20questions.&icon=brand-python"}],["$","link","20",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
1:null
e:I[86674,["9799","static/chunks/ec2b4425-50329b410e00a9c1.js","410","static/chunks/410-dfbfd00e58277561.js","8147","static/chunks/8147-2d2d9a18bcb26f63.js","4943","static/chunks/4943-35d31b66abf795bc.js","9845","static/chunks/9845-90dbd3909d8334b6.js","7434","static/chunks/7434-f6281683c5e91034.js","8227","static/chunks/8227-c7f40788707044e3.js","8391","static/chunks/8391-8e80deddf75f281d.js","6280","static/chunks/6280-3af59a266a2c907a.js","1454","static/chunks/1454-85873996a062b942.js","6925","static/chunks/6925-36f6d5bcbc50abaf.js","2034","static/chunks/2034-d624f0c0cac89e79.js","6300","static/chunks/app/(navigation)/presets/preset/%5Bslug%5D/page-b11fd8b663e66e83.js"],"PresetDetail"]
f:T5b7,You are Python Developer that provides expert-level insights and solutions in data structures and algorithms.
  Your responses should include examples of code snippets (where applicable), best practices, and explanations of underlying concepts.

  Here are some rules:
  - Use the latest stable version of Python.
  - Provide real-world examples or code snippets to illustrate solutions.
  - Prefer standard library functions and modules whenever possible, and limit use of third-party packages to those that are well-maintained and commonly used in the industry.
  - Include links to reputable sources for further reading (when beneficial), prefer official documentation.
  - For each problem I present to you, please guide me through the following stages:
  Step 1: Understanding and Visualization - I'd like you to help me draw a representative example or diagram, to better understand the problem and its constraints.
  Step 2: Brute Force Approach - Let's discuss a simple but potentially inefficient way to solve the problem. This will serve as our baseline strategy.
  Step 3: Optimization - From here, we should brainstorm possible ways to improve our brute force solution.
  We might consider different algorithms, data structures, or computational techniques that could make our solution more efficient in terms of time and space complexity.
  Step 4: Walk-through - Now, I'd like you to walk me through the optimized solution using our initial example.2:["$","$Le",null,{"preset":{"id":"python-technical-interview-expert","name":"Technical Interview Expert","instructions":"$f","description":"A Python Expert helping you through technical interview questions.","icon":"brand-python","creativity":"low","model":"openai-gpt-4o","web_search":true,"date":"2024-04-24","author":{"name":"Simon Ayotte","link":"https://github.com/simonayotte"}},"relatedPresets":[{"id":"code-reviewer","name":"Code Reviewer","instructions":"You are a developer tasked with providing detailed, constructive feedback on code snippets across various programming languages. Your responses should focus on improving code quality, readability, and adherence to best practices.\n\nHere are the rules you must follow:\n- Analyze the code for potential errors and suggest corrections.\n- Offer improvements on code efficiency and maintainability.\n- Highlight any deviations from standard coding practices.\n- Encourage the use of comments or documentation where necessary.\n- Suggest better variable, function, or class names if you see fit.\n- Detail alternative approaches and their advantages when relevant.\n- When possible, refer to official guidelines or documentation to support your recommendations.\"\n","description":"Provides feedback on code quality and best practices.","icon":"magnifying-glass","creativity":"low","model":"anthropic-claude-opus","date":"2024-03-26"},{"id":"logo-designer","name":"Logo Ideas","instructions":"You are a graphic designer that specializes in logo design.\n\nHere are the rules you must follow:\n- Always reply with an image generation of a logotype.\n- The logo is minimalist and without text\n- Max 1-2 simple shapes, don't use a lot of elements\n- Only reply with 1 (one) image\n- Don't include other elements inside the image like backgrounds, props, or extras - only the logo shape","description":"Generates logo ideas for your business or hobby.","icon":"image","creativity":"maximum","model":"openai-gpt-4o","image_generation":true,"date":"2024-05-15"}],"models":[{"id":"openai-gpt-3.5-turbo","name":"GPT-3.5 Turbo","description":"GPT-3.5 Turbo is OpenAI’s fastest model, making it ideal for tasks that require quick response times with basic language processing capabilities.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["chat","quick_ai","commands"],"capabilities":{"web_search":"full","image_generation":"full"},"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-2"}},"in_better_ai_subscription":false,"model":"gpt-3.5-turbo","provider":"openai","provider_name":"OpenAI","provider_brand":"openai","speed":3,"intelligence":3,"requires_better_ai":false,"context":16},{"id":"openai-gpt-4","name":"GPT-4","description":"GPT-4 is OpenAI’s most capable model with broad general knowledge, allowing it to follow complex instructions and solve difficult problems.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[],"capabilities":{"web_search":"full","image_generation":"full"},"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"}},"in_better_ai_subscription":true,"model":"gpt-4","provider":"openai","provider_name":"OpenAI","provider_brand":"openai","speed":1,"intelligence":4,"requires_better_ai":true,"context":8},{"id":"openai-gpt-4-turbo","name":"GPT-4 Turbo","description":"GPT-4 Turbo from OpenAI has a big context window that fits hundreds of pages of text, making it a great choice for workloads that involve longer prompts.\n","availability":"public","status":"beta","features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[],"capabilities":{"web_search":"full","image_generation":"full"},"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"}},"in_better_ai_subscription":true,"model":"gpt-4-turbo","provider":"openai","provider_name":"OpenAI","provider_brand":"openai","speed":2,"intelligence":5,"requires_better_ai":true,"context":127},{"id":"openai-gpt-4o","name":"GPT-4o","description":"GPT-4o is the most advanced and fastest model from OpenAI, making it a great choice for complex everyday problems and deeper conversations.\n","availability":"public","status":"beta","features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["chat"],"capabilities":{"web_search":"full","image_generation":"full"},"abilities":{"web_search":{"toggleable":true},"image_generation":{"model":"dall-e-3"},"vision":{"formats":["image/png","image/jpeg","image/webp","image/gif"]}},"in_better_ai_subscription":true,"model":"gpt-4o","provider":"openai","provider_name":"OpenAI","provider_brand":"openai","speed":3,"intelligence":5,"requires_better_ai":true,"context":127},{"id":"anthropic-claude-haiku","name":"Claude 3 Haiku","description":"Claude 3 Haiku is Anthropic's fastest model, with a large context window that makes it ideal for analyzing code, documents, or large amounts of text.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api"],"suggestions":["quick_ai"],"capabilities":{"web_search":"full"},"abilities":{"web_search":{"toggleable":true},"vision":{"formats":["image/png","image/jpeg","image/webp","image/gif"]}},"in_better_ai_subscription":false,"model":"claude-3-haiku-20240307","provider":"anthropic","provider_name":"Anthropic","provider_brand":"anthropic","speed":3,"intelligence":3,"requires_better_ai":false,"context":200},{"id":"anthropic-claude-sonnet","name":"Claude 3.5 Sonnet","description":"Claude 3.5 Sonnet from Anthropic has enhanced intelligence with increased speed. It excels at complex tasks like visual reasoning or workflow orchestrations.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api"],"suggestions":["commands","chat"],"capabilities":{"web_search":"full"},"abilities":{"web_search":{"toggleable":true},"vision":{"formats":["image/png","image/jpeg","image/webp","image/gif"]}},"in_better_ai_subscription":true,"model":"claude-3-5-sonnet-20240620","provider":"anthropic","provider_name":"Anthropic","provider_brand":"anthropic","speed":3,"intelligence":5,"requires_better_ai":true,"context":200},{"id":"anthropic-claude-opus","name":"Claude 3 Opus","description":"Claude 3 Opus is Anthropic's most intelligent model, with best-in-market performance on highly complex tasks. It stands out for remarkable fluency.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api"],"suggestions":[],"capabilities":{"web_search":"full"},"abilities":{"web_search":{"toggleable":true},"vision":{"formats":["image/png","image/jpeg","image/webp","image/gif"]}},"in_better_ai_subscription":true,"model":"claude-3-opus-20240229","provider":"anthropic","provider_name":"Anthropic","provider_brand":"anthropic","speed":1,"intelligence":4,"requires_better_ai":true,"context":200},{"id":"perplexity-llama-3-sonar-small-32k-online","name":"Llama 3 Sonar Small","description":"Perplexity's Llama 3 Sonar Small is built for speed. It quickly gives you helpful answers using the latest internet knowledge while minimizing hallucinations.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["quick_ai"],"capabilities":{"web_search":"always_on"},"abilities":{"web_search":{"toggleable":false}},"in_better_ai_subscription":false,"model":"llama-3-sonar-small-32k-online","provider":"perplexity","provider_name":"Perplexity","provider_brand":"perplexity","speed":3,"intelligence":1,"requires_better_ai":false,"context":28},{"id":"perplexity-llama-3-sonar-large-32k-online","name":"Llama 3 Sonar Large","description":"Perplexity's most advanced model, Llama 3 Sonar Large, can handle complex questions. It considers current web knowledge to provide well-reasoned, in-depth answers.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["quick_ai"],"capabilities":{"web_search":"always_on"},"abilities":{"web_search":{"toggleable":false}},"in_better_ai_subscription":true,"model":"llama-3-sonar-large-32k-online","provider":"perplexity","provider_name":"Perplexity","provider_brand":"perplexity","speed":2,"intelligence":2,"requires_better_ai":true,"context":28},{"id":"groq-llama3-70b-8192","name":"Llama 3 70B","description":"Llama 3 70B from Meta is the most capable openly available LLM which can serve as a tool for various text-related tasks. Powered by Groq.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":["commands"],"capabilities":{},"abilities":{"web_search":{"toggleable":true}},"in_better_ai_subscription":false,"model":"llama3-70b-8192","provider":"groq","provider_name":"Meta","provider_brand":"meta","speed":5,"intelligence":4,"requires_better_ai":false,"context":8},{"id":"groq-mixtral-8x7b-32768","name":"Mixtral 8x7B","description":"Mixtral 8x7B from Mistral is an open-source model that demonstrates high performance in generating code and text at an impressive speed. Powered by Groq.\n","availability":"public","status":null,"features":["chat","quick_ai","commands","api","emoji_search"],"suggestions":[],"capabilities":{},"abilities":{"web_search":{"toggleable":true}},"in_better_ai_subscription":false,"model":"mixtral-8x7b-32768","provider":"groq","provider_name":"Mistral","provider_brand":"mistral","speed":5,"intelligence":3,"requires_better_ai":false,"context":32}]}]
